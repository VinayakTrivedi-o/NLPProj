{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 2793257,
          "sourceType": "datasetVersion",
          "datasetId": 1705886
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        " # IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "davidmckinley_all_the_news_dataset_path = kagglehub.dataset_download('davidmckinley/all-the-news-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "SthO-71yafzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "966e65a7-1008-4980-d8d4-7ba49675976b"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/davidmckinley/all-the-news-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.16G/3.16G [00:35<00:00, 95.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:39:46.896543Z",
          "iopub.execute_input": "2025-09-23T16:39:46.897279Z",
          "iopub.status.idle": "2025-09-23T16:39:47.177282Z",
          "shell.execute_reply.started": "2025-09-23T16:39:46.89725Z",
          "shell.execute_reply": "2025-09-23T16:39:47.176554Z"
        },
        "id": "-pWE2XGRafzN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions httpx beautifulsoup4 nltk"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:39:47.178514Z",
          "iopub.execute_input": "2025-09-23T16:39:47.178852Z",
          "iopub.status.idle": "2025-09-23T16:39:53.157012Z",
          "shell.execute_reply.started": "2025-09-23T16:39:47.178832Z",
          "shell.execute_reply": "2025-09-23T16:39:53.156057Z"
        },
        "id": "IEKq10loafzO",
        "outputId": "8d057d4c-719e-421d-9fb8-02c3157feca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (0.28.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx) (0.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx) (1.3.1)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.3 contractions-0.1.73 pyahocorasick-2.2.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install polars\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:39:53.158664Z",
          "iopub.execute_input": "2025-09-23T16:39:53.159Z",
          "iopub.status.idle": "2025-09-23T16:39:56.374304Z",
          "shell.execute_reply.started": "2025-09-23T16:39:53.158977Z",
          "shell.execute_reply": "2025-09-23T16:39:56.373395Z"
        },
        "id": "GEpO6ZmKafzO",
        "outputId": "16844e07-b309-4492-849c-107e0ea13ed7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (1.25.2)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-genai"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:39:56.376979Z",
          "iopub.execute_input": "2025-09-23T16:39:56.377249Z",
          "iopub.status.idle": "2025-09-23T16:40:00.418004Z",
          "shell.execute_reply.started": "2025-09-23T16:39:56.377227Z",
          "shell.execute_reply": "2025-09-23T16:40:00.41731Z"
        },
        "id": "cdN5kZCbafzO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:40:00.419029Z",
          "iopub.execute_input": "2025-09-23T16:40:00.419257Z",
          "iopub.status.idle": "2025-09-23T16:40:48.891229Z",
          "shell.execute_reply.started": "2025-09-23T16:40:00.419236Z",
          "shell.execute_reply": "2025-09-23T16:40:48.890187Z"
        },
        "_kg_hide-input": false,
        "_kg_hide-output": true,
        "id": "43VjTOBwafzP",
        "outputId": "6c538ad6-709c-486f-b844-4f84be759a43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.9)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.17.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.4)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.35.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=cfa139f5efeb291e87a7a2ea60d53daa2e524788339fbf702b952a8dc45b3e59\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, coloredlogs, onnxruntime, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.1.0 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.2.0 onnxruntime-1.22.1 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-proto-1.37.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#dependencies\n",
        "\n",
        "import numpy as np\n",
        "import nltk\n",
        "import contractions #contractions are I'll <-> I will\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from typing import List, Tuple\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import requests\n",
        "import os\n",
        "import httpx\n",
        "#import pandas as pd -> not using pandas due to memory constraints\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import polars as pl\n",
        "import pandas as pd\n",
        "import time\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import uuid\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:40:48.892491Z",
          "iopub.execute_input": "2025-09-23T16:40:48.892823Z",
          "iopub.status.idle": "2025-09-23T16:41:27.835976Z",
          "shell.execute_reply.started": "2025-09-23T16:40:48.892787Z",
          "shell.execute_reply": "2025-09-23T16:41:27.835328Z"
        },
        "id": "FB15D3cIafzP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(['punkt','stopwords','wordnet','punkt_tab'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:41:27.836801Z",
          "iopub.execute_input": "2025-09-23T16:41:27.837482Z",
          "iopub.status.idle": "2025-09-23T16:41:28.180093Z",
          "shell.execute_reply.started": "2025-09-23T16:41:27.83745Z",
          "shell.execute_reply": "2025-09-23T16:41:28.179501Z"
        },
        "id": "svmvFSq5afzP",
        "outputId": "3cde4909-8f77-4987-b15b-0f04c72aa3f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading my data\n",
        "\n",
        "path = davidmckinley_all_the_news_dataset_path\n",
        "\n",
        "\n",
        "df = pl.scan_csv(path,ignore_errors = True)\n",
        "print(df.head(1).collect())\n",
        "df_collected = df.collect()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:41:28.180842Z",
          "iopub.execute_input": "2025-09-23T16:41:28.181114Z",
          "iopub.status.idle": "2025-09-23T16:43:49.820399Z",
          "shell.execute_reply.started": "2025-09-23T16:41:28.181096Z",
          "shell.execute_reply": "2025-09-23T16:43:49.819486Z"
        },
        "id": "9f_kb0c-afzQ",
        "outputId": "f22ab333-dc6d-4c5c-d50a-88d4e1e01ec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (1, 12)\n",
            "┌─────┬────────────┬──────────────┬──────┬───┬──────────────┬──────────────┬─────────┬─────────────┐\n",
            "│     ┆ Unnamed: 0 ┆ date         ┆ year ┆ … ┆ article      ┆ url          ┆ section ┆ publication │\n",
            "│ --- ┆ ---        ┆ ---          ┆ ---  ┆   ┆ ---          ┆ ---          ┆ ---     ┆ ---         │\n",
            "│ i64 ┆ i64        ┆ str          ┆ i64  ┆   ┆ str          ┆ str          ┆ str     ┆ str         │\n",
            "╞═════╪════════════╪══════════════╪══════╪═══╪══════════════╪══════════════╪═════════╪═════════════╡\n",
            "│ 0   ┆ 0          ┆ 2016-12-09   ┆ 2016 ┆ … ┆ This post is ┆ https://www. ┆ null    ┆ Vox         │\n",
            "│     ┆            ┆ 18:31:00     ┆      ┆   ┆ part of      ┆ vox.com/poly ┆         ┆             │\n",
            "│     ┆            ┆              ┆      ┆   ┆ Polyarchy…   ┆ archy/…      ┆         ┆             │\n",
            "└─────┴────────────┴──────────────┴──────┴───┴──────────────┴──────────────┴─────────┴─────────────┘\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = df_collected['article'][1]\n",
        "print(text1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:43:49.821317Z",
          "iopub.execute_input": "2025-09-23T16:43:49.822013Z",
          "iopub.status.idle": "2025-09-23T16:43:49.829981Z",
          "shell.execute_reply.started": "2025-09-23T16:43:49.821991Z",
          "shell.execute_reply": "2025-09-23T16:43:49.829181Z"
        },
        "id": "QUUAvL48afzQ",
        "outputId": "5a31ca0d-618f-4a29-b3de-097fa4fad59e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The Indianapolis Colts made Andrew Luck the highest-paid player in NFL history this offseason with a five-year, $122-million contract with $89 million guaranteed. However, they're already finding that Luck's contract is inhibiting their ability to address weaknesses on other parts of the roster, particularly on defense. On Friday, Colts GM Ryan Grigson, who is under fire for the Colts 1-3 start, said that it's difficult to build up the team's defense with Luck making so much money. According to Keefer, Grigson did point out that the Colts still have young talent they're hoping to develop on defense. However, blaming Luck's contract — which the Colts gave him — for having a weak defense (30th in defensive DVOA) is not accurate. As others have pointed out, last year's Denver Broncos paid Peyton Manning $15 million in base salary while also boasting an elite defense. Luck also takes up $18.4 million against the salary cap this year, less than $1 million more than Manning did a year ago ($17.5 million). Much of this comes from drafting successfully, which the Colts have not done as well as elite teams like the Broncos or the Patriots, for instance. Now, with the Colts handcuffed to Luck's contract, drafting is going to become especially important, as will the use of whatever money they have in free agency. It's certainly possible to build a good defense with a high-paid quarterback, but if the Colts felt that paying Luck such a high sum of money would be difficult, perhaps they should have reconsidered what the final numbers. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The highest-paid player on all 32 NFL teams\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch first 900 rows\n",
        "df_900 = df.fetch(900)\n",
        "\n",
        "# Columns to drop (by index)\n",
        "cols_to_drop = [0,1,2,3,4,5,6,9,10,11]\n",
        "\n",
        "# Keep only columns NOT in cols_to_drop\n",
        "cols_to_keep = [col for i, col in enumerate(df_900.columns) if i not in cols_to_drop]\n",
        "\n",
        "# Select only the remaining columns\n",
        "df_900 = df_900.select(cols_to_keep)\n",
        "\n",
        "# Write CSV\n",
        "df_900.write_csv(\"Articles.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:43:49.832568Z",
          "iopub.execute_input": "2025-09-23T16:43:49.833105Z",
          "iopub.status.idle": "2025-09-23T16:44:11.623783Z",
          "shell.execute_reply.started": "2025-09-23T16:43:49.833083Z",
          "shell.execute_reply": "2025-09-23T16:44:11.618944Z"
        },
        "id": "Jdnig_VrafzQ",
        "outputId": "e682c56d-cd7e-47d6-b7b2-2a35fd1f6250",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2095565250.py:2: DeprecationWarning: `LazyFrame.fetch` is deprecated. `LazyFrame.fetch` is deprecated; use `LazyFrame.collect` instead, in conjunction with a call to `head`.\n",
            "  df_900 = df.fetch(900)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_art = \"/kaggle/working/Articles.csv\"\n",
        "df2 = pd.read_csv(path_to_art)\n",
        "df2.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:44:11.6252Z",
          "iopub.execute_input": "2025-09-23T16:44:11.625528Z",
          "iopub.status.idle": "2025-09-23T16:44:11.836992Z",
          "shell.execute_reply.started": "2025-09-23T16:44:11.6255Z",
          "shell.execute_reply": "2025-09-23T16:44:11.836165Z"
        },
        "id": "zrwAiUD9afzR",
        "outputId": "91143dee-33d2-46d9-dca6-404af0b59b87"
      },
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                               title  \\\n0  We should take concerns about the health of li...   \n1  Colts GM Ryan Grigson says Andrew Luck's contr...   \n2       Trump denies report he ordered Mueller fired   \n3  France's Sarkozy reveals his 'Passions' but in...   \n4  Paris Hilton: Woman In Black For Uncle Monty's...   \n\n                                             article  \n0  This post is part of Polyarchy, an independent...  \n1   The Indianapolis Colts made Andrew Luck the h...  \n2  DAVOS, Switzerland (Reuters) - U.S. President ...  \n3  PARIS (Reuters) - Former French president Nico...  \n4  Paris Hilton arrived at LAX Wednesday dressed ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>article</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>We should take concerns about the health of li...</td>\n      <td>This post is part of Polyarchy, an independent...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Colts GM Ryan Grigson says Andrew Luck's contr...</td>\n      <td>The Indianapolis Colts made Andrew Luck the h...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Trump denies report he ordered Mueller fired</td>\n      <td>DAVOS, Switzerland (Reuters) - U.S. President ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>France's Sarkozy reveals his 'Passions' but in...</td>\n      <td>PARIS (Reuters) - Former French president Nico...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Paris Hilton: Woman In Black For Uncle Monty's...</td>\n      <td>Paris Hilton arrived at LAX Wednesday dressed ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df2.tail()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:44:11.838236Z",
          "iopub.execute_input": "2025-09-23T16:44:11.838875Z",
          "iopub.status.idle": "2025-09-23T16:44:11.846573Z",
          "shell.execute_reply.started": "2025-09-23T16:44:11.838857Z",
          "shell.execute_reply": "2025-09-23T16:44:11.845848Z"
        },
        "id": "F9yBXgEWafzR",
        "outputId": "6aefda92-5ba3-42f8-8887-6710f1ac36b5"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                 title  \\\n895  How to use Sallie Krawcheck's Ellevest investi...   \n896    Ragnar Kjartansson’s Panorama of Love and Death   \n897  China-U.S. trade talks 'making a final sprint'...   \n898  Naveen Jain wants to send people to the moon, ...   \n899  Trump says U.S. farmers to get $15 billion in ...   \n\n                                               article  \n895   Investing — when done right — is one of the b...  \n896  The artist’s Death Is Elsewhere conveys an und...  \n897  SHANGHAI (Reuters) - Chinese state media on Sa...  \n898  Naveen Jain has a number of moonshot projects ...  \n899  WASHINGTON (Reuters) - President Donald Trump ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>article</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>895</th>\n      <td>How to use Sallie Krawcheck's Ellevest investi...</td>\n      <td>Investing — when done right — is one of the b...</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>Ragnar Kjartansson’s Panorama of Love and Death</td>\n      <td>The artist’s Death Is Elsewhere conveys an und...</td>\n    </tr>\n    <tr>\n      <th>897</th>\n      <td>China-U.S. trade talks 'making a final sprint'...</td>\n      <td>SHANGHAI (Reuters) - Chinese state media on Sa...</td>\n    </tr>\n    <tr>\n      <th>898</th>\n      <td>Naveen Jain wants to send people to the moon, ...</td>\n      <td>Naveen Jain has a number of moonshot projects ...</td>\n    </tr>\n    <tr>\n      <th>899</th>\n      <td>Trump says U.S. farmers to get $15 billion in ...</td>\n      <td>WASHINGTON (Reuters) - President Donald Trump ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2['article'][0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:44:11.847311Z",
          "iopub.execute_input": "2025-09-23T16:44:11.847488Z",
          "iopub.status.idle": "2025-09-23T16:44:11.86506Z",
          "shell.execute_reply.started": "2025-09-23T16:44:11.847474Z",
          "shell.execute_reply": "2025-09-23T16:44:11.864295Z"
        },
        "id": "OYWKkABpafzR",
        "outputId": "27ff39d3-d58a-4306-acd7-cbfb4014c894"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "This post is part of Polyarchy, an independent blog produced by the political reform program at New America, a Washington think tank devoted to developing new ideas and new voices. Imagine you are an otherwise healthy 30-something who starts feeling weird. You are sometimes short of breath. You get migraines. Your feet start to swell a little. But otherwise, everything seems fine. You go to the doctor. The doctor runs some tests. She tells you, It's probably nothing, but these could be signs of a coming heart attack. You push for more certainty, but the doctor tells you she's not sure. The human body is a complex system. You're young and otherwise pretty healthy. There could be plenty of other explanations for what you're feeling. But it is a little worrying. So just to be on the safe side, maybe you should reduce the stress in your life and eat a healthier diet. What would you do? If you're a sensible person, you'd probably err on the side of precaution. Sure, it might be nothing to worry about, and the likelihood of a heart attack in your 30s might be low. But even a low chance is a low chance of something possibly fatal. Why take a chance, especially when the recommendations — less stress, healthier diet — are good for you either way? I offer this parable as a way of thinking about the debate that's emerged over the past two weeks in response to Amanda Taub's New York Times article profiling new findings by Roberto Stefan Foa and Yascha Mounk — findings that raise alarms about the fact that younger people have, over time, become less and less likely to say in surveys that it is \"essential\" to live in a democracy. Rather than share the sense of alarm, however, several critics have jumped on Foa and Mounk for misinterpreting the data and generating unnecessary panic. Political scientist Erik Voeten, for example, argued that their analysis is misleading: \"The article by Mounk and Foa does document some small shifts in opinion on related issues. But these aren't nearly as dramatic as the New York Times graph suggests.\" Similarly, Wonkblog's Jeff Guo reanalyzed the data and argued that it is \"far less alarming than it seems.\" Foa and Mounk have responded, drawing on more analysis from their forthcoming Journal of Democracy article, which also documents increasing support among young people for \"a strong leader\" and rising support for extremism. Voeten, however, remains unimpressed, and now has more charts here suggesting the shifts are far less significant than Foa and Mounk make them out to be. \"And,\" he argues, \"it's dangerous too to tell the world that people are now ready to accept nondemocratic governance.\" For those who want to argue over how to interpret the data, you should follow the hyperlinks above. There are very reasonable points of disagreement. I don't have much to add to that debate here, other than to observe that it's very rare that data is unambiguous about important societal shifts before those shifts actually occur. When the data is unambiguous, it is almost always too late to do anything. The only sure sign of having a heart attack is, well, having a heart attack. Similarly, the only sure sign of a democratic collapse is, well, a democratic collapse. And whatever you think of the data analysis, there is also a mounting series of actual real-world election results that are hard to explain if support for liberal democracy is thriving. In deciding how seriously to take these findings, it's also worth asking what we would do differently if we took Foa and Mounk's findings seriously. How would we collectively respond? And what would be the consequences? For one, we'd probably invest in a lot more civic education, so that the next generation learns the basics of liberal democracy and understands why it's a better system than authoritarian rule. This seems like a good idea regardless. Similarly, we might collectively invest considerable resources in making a strong public case for liberal democracy. We might also try to figure out ways to make our public institutions do more outreach to citizens to make sure they feel engaged in their democracy, and think hard about building up intermediary institutions that help people feel as though their voices are represented and taken seriously. Again, these seem like things we should be doing regardless, like reducing stress or improving the health of our diets. In my heart attack parable, if the doctor had told you that the only way to prevent a future heart attack would be to give up your job and your social life and spend the next year on strict bed rest eating only kale and chia seed salads, you might want to be a little more certain that you really were at high risk for a heart attack. After all, taking the risk seriously would impose a heavy cost on you. Other recent crises offer some examples of cases where key decision-makers did ignore warning signs, because taking those signs seriously would have imposed significant costs on them. For example, in the housing bubble of the mid-2000s, warnings were ignored because the financial industry had staked considerable investments and product lines on the myth that housing values would go up forever. To admit that housing was overvalued and that securitized mortgages were riskier than advertised would have cost investment banks dearly. But eventually, reality caught up with them, and the resulting damage was far worse than it would have been if we had paid attention to the early warning signs. Similarly, many carbon-intensive industries and fossil fuel producers pushed back on findings of climate change because taking those findings seriously would force significant changes in their industries. As a result, these industries funded doubt and uncertainty. The problem has since gotten much worse, and it has become harder to take effective action. The early scientists may have been alarmist. But we'd be in much better shape if we had listened to them. I would be more comforted if I could be certain that Voeten is right and Foa and Mounk are wrong. Maybe there is indeed nothing to worry about. But given the risks, as well as the recent string of election results, I'd rather err on the side of caution. Like the threat of a heart attack, the threat of autocracy or military rule replacing liberal democracy is pretty serious, and very difficult to recover from. I don't want to take a chance. Especially when the preventive medicine consists of things we should probably be doing anyway.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "4hGTh5bSafzR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling the Gemini API\n",
        "\n",
        "GEMINI_API_KEY = \"AIzaSyCYfoNXiB0K8mRCrLobewA1UNLzC68hHMA\"\n",
        "#the text is the article-> I need to run this for the entire texts in the dataframe.\n",
        "def theme_identification(text,API):\n",
        "    # The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
        "    client = genai.Client(api_key=API)\n",
        "    text = text\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash-lite\",\n",
        "        config=types.GenerateContentConfig(\n",
        "            system_instruction=\"You are a theme identification agent. You wll be given text as input and you have to identify the theme and topic of the text provided. You should format your output like 'Theme: {theme}; Topic: {topic}' \"),\n",
        "        contents= text\n",
        "    )\n",
        "    #print(response.text)\n",
        "    theme = response.text\n",
        "    theme = re.findall(\":([^;]+)\",theme)\n",
        "    return theme"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:44:11.865904Z",
          "iopub.execute_input": "2025-09-23T16:44:11.86653Z",
          "iopub.status.idle": "2025-09-23T16:44:11.883949Z",
          "shell.execute_reply.started": "2025-09-23T16:44:11.866504Z",
          "shell.execute_reply": "2025-09-23T16:44:11.883255Z"
        },
        "id": "fqNWjY6KafzR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "GOOGLE_SEARCH_API = \"AIzaSyA22iCi3Es9iZiycYNbMKiH-UlpUJXNlP8\"\n",
        "SEARCH_ENGINE_ID = \"82073fa35642e4b81\"\n",
        "\n",
        "TOP_K = 10\n",
        "PAGE_SIZE = 10  # API returns max 10 per request\n",
        "\n",
        "def google_search(api_key, search_engine_id, query, start=1):\n",
        "    base_url = \"https://www.googleapis.com/customsearch/v1\"\n",
        "    params = {\n",
        "        \"key\": api_key,\n",
        "        \"cx\": search_engine_id,\n",
        "        \"q\": query,\n",
        "        \"start\": start\n",
        "    }\n",
        "    resp = requests.get(base_url, params=params)\n",
        "    resp.raise_for_status()\n",
        "    return resp.json().get(\"items\", [])\n",
        "\n",
        "# generator to fetch results in pages\n",
        "def fetch_top_k_results(api_key, search_engine_id, query, top_k=TOP_K):\n",
        "    results = []\n",
        "    for start in range(1, top_k + 1, PAGE_SIZE):\n",
        "        items = google_search(api_key, search_engine_id, query, start=start)\n",
        "        if not items:\n",
        "            break\n",
        "        for item in items:\n",
        "            results.append(item)\n",
        "            if len(results) >= top_k:\n",
        "                return results\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "'''# normalize only top_k items\n",
        "df = pd.json_normalize(search_results)\n",
        "df.to_csv(\"search_results.csv\", index=False)\n",
        "\n",
        "# extract links\n",
        "links = df[\"link\"].tolist()[:TOP_K]\n",
        "print(links)'''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:44:11.884634Z",
          "iopub.execute_input": "2025-09-23T16:44:11.884798Z",
          "iopub.status.idle": "2025-09-23T16:44:11.912185Z",
          "shell.execute_reply.started": "2025-09-23T16:44:11.884785Z",
          "shell.execute_reply": "2025-09-23T16:44:11.911559Z"
        },
        "id": "gZg7RzhcafzR",
        "outputId": "ea1d573a-0e18-4a32-fe47-4313b1f5de83"
      },
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'# normalize only top_k items\\ndf = pd.json_normalize(search_results)\\ndf.to_csv(\"search_results.csv\", index=False)\\n\\n# extract links\\nlinks = df[\"link\"].tolist()[:TOP_K]\\nprint(links)'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Global variables for the embedding model and ChromaDB client ---\n",
        "# We initialize these once to avoid reloading them on every function call.\n",
        "print(\"Loading sentence-transformer model... (This may take a moment on first run)\")\n",
        "EMBEDDING_MODEL = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "CHROMA_CLIENT = chromadb.Client()\n",
        "\n",
        "# Create or get a collection in ChromaDB. Collections are like tables in a traditional DB.\n",
        "# The embedding function is automatically handled by ChromaDB if we provide a SentenceTransformer model.\n",
        "COLLECTION = CHROMA_CLIENT.get_or_create_collection(\n",
        "    name=\"web_scrapes\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"} # Specifies the similarity metric\n",
        ")\n",
        "\n",
        "def scrape_website(url):\n",
        "    \"\"\"\n",
        "    Scrapes the text content from a given URL.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL of the website to scrape.\n",
        "\n",
        "    Returns:\n",
        "        str: The extracted text content of the website, or an error message if scraping fails.\n",
        "    \"\"\"\n",
        "    print(f\"Scraping: {url}\")\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        response = requests.get(url, headers=headers, timeout=15)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        for script_or_style in soup(['script', 'style']):\n",
        "            script_or_style.decompose()\n",
        "\n",
        "        text = soup.get_text()\n",
        "        lines = (line.strip() for line in text.splitlines())\n",
        "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "        cleaned_text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "        return cleaned_text\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        error_message = f\"Error scraping {url}: {e}\"\n",
        "        print(error_message)\n",
        "        return error_message\n",
        "\n",
        "\n",
        "def chunk_text(text: str, chunk_size: int = 500, overlap: int = 50):\n",
        "    if not text:\n",
        "        return []\n",
        "    chunks = []\n",
        "    pos = 0\n",
        "    n = len(text)\n",
        "    while pos < n:\n",
        "        end = pos + chunk_size\n",
        "        chunk = text[pos:end].strip()\n",
        "        if chunk:\n",
        "            chunks.append(chunk)\n",
        "        pos += chunk_size - overlap\n",
        "    return chunks\n",
        "\n",
        "def add_url_to_chroma(url: str,\n",
        "                      collection,\n",
        "                      embedding_model,\n",
        "                      chunk_size: int = 500,\n",
        "                      overlap: int = 50,\n",
        "                      encode_batch_size: int = 64):\n",
        "    content = scrape_website(url)   # uses your existing scrape_website\n",
        "    if not content or content.startswith(\"Error scraping\"):\n",
        "        print(f\"Skip {url}: no content or error\")\n",
        "        return 0\n",
        "\n",
        "    chunks = chunk_text(content, chunk_size=chunk_size, overlap=overlap)\n",
        "    if not chunks:\n",
        "        print(f\"Skip {url}: no chunks produced\")\n",
        "        return 0\n",
        "\n",
        "    ids = [str(uuid.uuid4()) for _ in chunks]\n",
        "    metadatas = [{\"source\": url, \"chunk_index\": i} for i in range(len(chunks))]\n",
        "\n",
        "    # create embeddings (numpy) then convert to native lists\n",
        "    embeddings = embedding_model.encode(\n",
        "        chunks,\n",
        "        batch_size=encode_batch_size,\n",
        "        show_progress_bar=False,\n",
        "        convert_to_numpy=True\n",
        "    )\n",
        "    if isinstance(embeddings, np.ndarray):\n",
        "        embeddings_list = embeddings.tolist()\n",
        "    else:\n",
        "        embeddings_list = list(embeddings)\n",
        "\n",
        "    collection.add(\n",
        "        ids=ids,\n",
        "        documents=chunks,\n",
        "        metadatas=metadatas,\n",
        "        embeddings=embeddings_list\n",
        "    )\n",
        "    print(f\"Added {len(chunks)} chunks from {url}\")\n",
        "    return len(chunks)\n",
        "\n",
        "def add_links_to_chroma(links: list,\n",
        "                        collection=COLLECTION,\n",
        "                        embedding_model=EMBEDDING_MODEL,\n",
        "                        delay: float = 1.0,\n",
        "                        **add_kwargs):\n",
        "    total = 0\n",
        "    for url in links:\n",
        "        try:\n",
        "            time.sleep(delay)\n",
        "            added = add_url_to_chroma(url, collection, embedding_model, **add_kwargs)\n",
        "            total += added\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {url}: {type(e).__name__}: {e}\")\n",
        "    print(f\"Done. Total chunks added: {total}\")\n",
        "    return total\n",
        "\n",
        "# Usage:\n",
        "# links is your list of URLs (from fetch_top_k_links or similar)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:44:11.913148Z",
          "iopub.execute_input": "2025-09-23T16:44:11.913407Z",
          "iopub.status.idle": "2025-09-23T16:44:21.578855Z",
          "shell.execute_reply.started": "2025-09-23T16:44:11.91339Z",
          "shell.execute_reply": "2025-09-23T16:44:21.5783Z"
        },
        "id": "MnEx6BcFafzS",
        "outputId": "426f6786-049e-43bb-da88-c3707e4b7e57",
        "colab": {
          "referenced_widgets": [
            "6dc4c6a9bdb74df59469d2327e0e3fed",
            "abab28bdf2a648abb8254aee371217ec",
            "0da0f79bf81e4fa2bb54523d54cd215c",
            "4b21faa2394641668c849abda0ddb5ac",
            "e7ccde7bd22b4643bc10d0989a3c3754",
            "e626cf1c5836435fb182296f03a60101",
            "24bdd8e5fada4736a95405a8e5db3786",
            "87eb78c8628744a4b13cce572222c50e",
            "bbf9e91c5488499887ae53287d7a1a39",
            "abd5a74a9ba94b849b33bc39349c5d33",
            "1c11bc8b79eb4c528b76142c4a04942f"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Loading sentence-transformer model... (This may take a moment on first run)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6dc4c6a9bdb74df59469d2327e0e3fed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abab28bdf2a648abb8254aee371217ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0da0f79bf81e4fa2bb54523d54cd215c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b21faa2394641668c849abda0ddb5ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7ccde7bd22b4643bc10d0989a3c3754"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e626cf1c5836435fb182296f03a60101"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24bdd8e5fada4736a95405a8e5db3786"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87eb78c8628744a4b13cce572222c50e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbf9e91c5488499887ae53287d7a1a39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abd5a74a9ba94b849b33bc39349c5d33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c11bc8b79eb4c528b76142c4a04942f"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#sentence scoring\n",
        "''' the logic of scoring should be in semantic search similarity score + sentence importance -> unique sentences where new info is given\n",
        "-> we then look for an appropriate threshold.\n",
        "-> Dataset will then be validated by running this over the texts of the dataset.\n",
        "\n",
        "Do we need an ML model here? I don't see the need for one. Will that be a drawback?\n",
        "What I can do is then train a ML model on the Annotated Dataset? -> But then whats the point? I have made this sentence scorer as my main logic\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def hybrid_sentence_scorer(original_sentences: list, collection, embedding_model, weights: tuple = (0.5, 0.3, 0.2)):\n",
        "    \"\"\"\n",
        "    Scores sentences using a hybrid model of vector similarity, TF-IDF, and position.\n",
        "\n",
        "    Args:\n",
        "        original_sentences (list): The list of original sentences from the text.\n",
        "        collection: The ChromaDB collection object.\n",
        "        embedding_model: The loaded SentenceTransformer model.\n",
        "        weights (tuple): A tuple of weights for (similarity, tfidf, position).\n",
        "\n",
        "    Returns:\n",
        "        list: A sorted list of tuples containing (final_score, sentence).\n",
        "    \"\"\"\n",
        "    if not original_sentences:\n",
        "        return []\n",
        "\n",
        "    w_sim, w_tfidf, w_pos = weights\n",
        "\n",
        "    # 1. Calculate TF-IDF scores\n",
        "    # We'll normalize these scores to be between 0 and 1\n",
        "    vect = TfidfVectorizer(token_pattern=r'(?u)\\\\b\\\\w+\\\\b')\n",
        "    tfidf_matrix = vect.fit_transform(original_sentences)\n",
        "    tfidf_scores = tfidf_matrix.sum(axis=1).A1\n",
        "    normalized_tfidf = tfidf_scores / np.max(tfidf_scores) if np.max(tfidf_scores) > 0 else tfidf_scores\n",
        "\n",
        "    # 2. Calculate Vector Similarity scores\n",
        "    # We query the DB for each sentence to get its relevance score\n",
        "    query_embeddings = embedding_model.encode(original_sentences)\n",
        "    query_results = collection.query(\n",
        "        query_embeddings=list(query_embeddings),\n",
        "        n_results=1 # We only need the top match for scoring\n",
        "    )\n",
        "    # The distance is often a measure of \"difference\", so we convert it to similarity\n",
        "    # For cosine similarity (default in your setup), score = 1 - distance\n",
        "    similarity_scores = [1 - dist[0] if dist else 0 for dist in query_results['distances']]\n",
        "    normalized_sim = np.array(similarity_scores) # Already in a ~0-1 range\n",
        "\n",
        "    # 3. Calculate Positional scores\n",
        "    # We give a decaying score from 1 (first sentence) to 0\n",
        "    positional_scores = np.linspace(1.0, 0.0, len(original_sentences))\n",
        "\n",
        "    # 4. Calculate Final Hybrid Score\n",
        "    final_scores = (w_sim * normalized_sim) + \\\n",
        "                   (w_tfidf * normalized_tfidf) + \\\n",
        "                   (w_pos * positional_scores)\n",
        "\n",
        "    # Combine scores with sentences and sort\n",
        "    scored_sentences = list(zip(final_scores, original_sentences))\n",
        "    scored_sentences.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    return scored_sentences\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:44:21.579622Z",
          "iopub.execute_input": "2025-09-23T16:44:21.580191Z",
          "iopub.status.idle": "2025-09-23T16:44:21.587247Z",
          "shell.execute_reply.started": "2025-09-23T16:44:21.580167Z",
          "shell.execute_reply": "2025-09-23T16:44:21.58652Z"
        },
        "id": "VAMlRuDFafzS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def article_score(text, weights=(0.5,0.3,0.2)):\n",
        "    \"\"\"\n",
        "    Returns the average hybrid score for an article.\n",
        "    \"\"\"\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    if not sentences:\n",
        "        return 0.0\n",
        "    scored = hybrid_sentence_scorer(sentences, COLLECTION, EMBEDDING_MODEL, weights=weights)\n",
        "    scores = [score for score, _ in scored]\n",
        "    avg_score = sum(scores) / len(scores)\n",
        "    return avg_score\n",
        "#running this for the entire dataset/"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:44:21.588015Z",
          "iopub.execute_input": "2025-09-23T16:44:21.588223Z",
          "iopub.status.idle": "2025-09-23T16:44:21.615312Z",
          "shell.execute_reply.started": "2025-09-23T16:44:21.588208Z",
          "shell.execute_reply": "2025-09-23T16:44:21.614786Z"
        },
        "id": "x8KnE3IkafzS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_collection(name):\n",
        "    CHROMA_CLIENT.delete_collection(name=name)\n",
        "    return CHROMA_CLIENT.create_collection(\n",
        "        name=name,\n",
        "        metadata={\"hnsw:space\": \"cosine\"}\n",
        "    )\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:44:21.615976Z",
          "iopub.execute_input": "2025-09-23T16:44:21.61626Z",
          "iopub.status.idle": "2025-09-23T16:44:21.632619Z",
          "shell.execute_reply.started": "2025-09-23T16:44:21.616233Z",
          "shell.execute_reply": "2025-09-23T16:44:21.63202Z"
        },
        "id": "JgUBwiqxafzS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "THRESHOLD = 0.4\n",
        "print(TOP_K)\n",
        "TOP_K= 2\n",
        "def article_label(article):\n",
        "    theme = theme_identification(article, GEMINI_API_KEY)\n",
        "    search_results = fetch_top_k_results(GOOGLE_SEARCH_API, SEARCH_ENGINE_ID, query=theme, top_k=TOP_K)\n",
        "    links = [item[\"link\"] for item in search_results[:TOP_K] if \"link\" in item]\n",
        "    add_links_to_chroma(links, delay=1.0)\n",
        "    articlescore = article_score(article)\n",
        "    _ = clear_collection(COLLECTION)\n",
        "    return \"Yes\" if articlescore >= THRESHOLD else \"No\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:44:21.633458Z",
          "iopub.execute_input": "2025-09-23T16:44:21.633926Z",
          "iopub.status.idle": "2025-09-23T16:44:21.650372Z",
          "shell.execute_reply.started": "2025-09-23T16:44:21.633908Z",
          "shell.execute_reply": "2025-09-23T16:44:21.649605Z"
        },
        "id": "KS53xyKwafzS",
        "outputId": "da4b3697-8798-4891-ba67-4992e7343a29"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "10\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "MAX_RETRIES = 1\n",
        "RATE_LIMIT_PER_MIN = 15\n",
        "INTERVAL = 60.0 / RATE_LIMIT_PER_MIN\n",
        "\n",
        "def process_df_rate_limited(df, article_col=\"article\", label_col=\"label\"):\n",
        "    df[label_col] = None\n",
        "    for idx, article in df[article_col].items():\n",
        "        print(f\"processing row {idx+1}/{len(df)} idx={idx}\")\n",
        "        if not isinstance(article, str) or not article.strip():\n",
        "            df.at[idx, label_col] = \"No\"\n",
        "            continue\n",
        "\n",
        "        attempt = 0\n",
        "        while attempt < MAX_RETRIES:\n",
        "            try:\n",
        "                df.at[idx, label_col] = article_label(article)\n",
        "                break\n",
        "            except Exception as e:\n",
        "                attempt += 1\n",
        "                time.sleep(INTERVAL * (2 ** (attempt - 1)))\n",
        "        else:\n",
        "            df.at[idx, label_col] = \"Error\"\n",
        "\n",
        "        time.sleep(INTERVAL)  # enforce Gemini rate limit between calls\n",
        "\n",
        "    return df\n",
        "df3 = process_df_rate_limited(df2)\n",
        "df3.head()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-23T16:44:21.651475Z",
          "iopub.execute_input": "2025-09-23T16:44:21.651707Z",
          "execution_failed": "2025-09-23T17:16:58.627Z"
        },
        "id": "lnfxHqHZafzT",
        "outputId": "2691e9bc-ea54-4176-add7-b08939a01316"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "processing row 1/900 idx=0\nScraping: https://www.sciencedirect.com/science/article/pii/S0190740920303078\nError scraping https://www.sciencedirect.com/science/article/pii/S0190740920303078: 400 Client Error: Bad Request for url: https://www.sciencedirect.com/unsupported_browser\nSkip https://www.sciencedirect.com/science/article/pii/S0190740920303078: no content or error\nScraping: https://pmc.ncbi.nlm.nih.gov/articles/PMC3158614/\nAdded 84 chunks from https://pmc.ncbi.nlm.nih.gov/articles/PMC3158614/\nDone. Total chunks added: 84\nprocessing row 2/900 idx=1\nScraping: https://www.indystar.com/story/sports/nfl/colts/2016/03/04/andrew-luck-effect-how-qbs-contract-impact-colts/81298098/\nAdded 18 chunks from https://www.indystar.com/story/sports/nfl/colts/2016/03/04/andrew-luck-effect-how-qbs-contract-impact-colts/81298098/\nScraping: https://www.colts.com/news/colts-mailbag-andrew-luck-s-contract-jalen-collins-role-and-braden-smith-s-futur\nAdded 39 chunks from https://www.colts.com/news/colts-mailbag-andrew-luck-s-contract-jalen-collins-role-and-braden-smith-s-futur\nDone. Total chunks added: 57\nprocessing row 3/900 idx=2\nScraping: https://www.acslaw.org/projects/the-presidential-investigation-education-project/other-resources/key-findings-of-the-mueller-report/\nAdded 27 chunks from https://www.acslaw.org/projects/the-presidential-investigation-education-project/other-resources/key-findings-of-the-mueller-report/\nScraping: https://en.wikipedia.org/wiki/Mueller_special_counsel_investigation\nAdded 317 chunks from https://en.wikipedia.org/wiki/Mueller_special_counsel_investigation\nDone. Total chunks added: 344\nprocessing row 4/900 idx=3\nScraping: https://en.wikipedia.org/wiki/Nicolas_Sarkozy\nAdded 294 chunks from https://en.wikipedia.org/wiki/Nicolas_Sarkozy\nScraping: https://www.france24.com/en/20140919-ex-president-sarkozy-announces-return-politics-ump-leadership-france\nError scraping https://www.france24.com/en/20140919-ex-president-sarkozy-announces-return-politics-ump-leadership-france: 403 Client Error: Forbidden for url: https://www.france24.com/en/20140919-ex-president-sarkozy-announces-return-politics-ump-leadership-france\nSkip https://www.france24.com/en/20140919-ex-president-sarkozy-announces-return-politics-ump-leadership-france: no content or error\nDone. Total chunks added: 294\nprocessing row 5/900 idx=4\nScraping: https://people.com/music/rihanna-uncle-dies-instagram-tribute-dad-ronald-fenty/\nAdded 17 chunks from https://people.com/music/rihanna-uncle-dies-instagram-tribute-dad-ronald-fenty/\nScraping: https://www.lifeandstylemag.com/posts/paris-hilton-uncle-death-monty-brinson-88676/\nAdded 16 chunks from https://www.lifeandstylemag.com/posts/paris-hilton-uncle-death-monty-brinson-88676/\nDone. Total chunks added: 33\nprocessing row 6/900 idx=5\nScraping: https://www.bis.org/publ/othp42_fin_stab.pdf\nError processing https://www.bis.org/publ/othp42_fin_stab.pdf: InternalError: ValueError: Batch size of 9238 is greater than max batch size of 5461\nScraping: https://www.imf.org/external/pubs/ft/wp/2016/wp16172.pdf\nError scraping https://www.imf.org/external/pubs/ft/wp/2016/wp16172.pdf: HTTPSConnectionPool(host='www.imf.org', port=443): Read timed out. (read timeout=15)\nSkip https://www.imf.org/external/pubs/ft/wp/2016/wp16172.pdf: no content or error\nDone. Total chunks added: 0\nprocessing row 7/900 idx=6\nScraping: https://www.bbc.com/news/world-latin-america-48743401\nAdded 12 chunks from https://www.bbc.com/news/world-latin-america-48743401\nScraping: https://buenosairesherald.com/world/international-relations/venezuela-confirms-arrest-of-argentine-military-police-officer\nAdded 13 chunks from https://buenosairesherald.com/world/international-relations/venezuela-confirms-arrest-of-argentine-military-police-officer\nDone. Total chunks added: 25\nprocessing row 8/900 idx=7\nDone. Total chunks added: 0\nprocessing row 9/900 idx=8\nScraping: https://caffeinecoding.com/google-io-2016-in-review/\nAdded 18 chunks from https://caffeinecoding.com/google-io-2016-in-review/\nScraping: https://developers.google.com/events\nAdded 60 chunks from https://developers.google.com/events\nDone. Total chunks added: 78\nprocessing row 10/900 idx=9\nScraping: https://carnegieendowment.org/research/2024/01/countering-disinformation-effectively-an-evidence-based-policy-guide?lang=en\nAdded 664 chunks from https://carnegieendowment.org/research/2024/01/countering-disinformation-effectively-an-evidence-based-policy-guide?lang=en\nScraping: https://www.accc.gov.au/system/files/ACCC+commissioned+report+-+The+impact+of+digital+platforms+on+news+and+journalistic+content,+Centre+for+Media+Transition+(2).pdf\nError processing https://www.accc.gov.au/system/files/ACCC+commissioned+report+-+The+impact+of+digital+platforms+on+news+and+journalistic+content,+Centre+for+Media+Transition+(2).pdf: InternalError: ValueError: Batch size of 6193 is greater than max batch size of 5461\nDone. Total chunks added: 664\nprocessing row 11/900 idx=10\nScraping: https://crossworks.holycross.edu/cgi/viewcontent.cgi?article=1027&context=honors\nAdded 2494 chunks from https://crossworks.holycross.edu/cgi/viewcontent.cgi?article=1027&context=honors\nScraping: https://www.capecodcommission.org/resource-library/file/?url=/dept/commission/team/Website_Resources/housing/CLT-HLB/Cape%20Cod%20CLT%20HLB%20Establishment%20Planning%20Report.pdf\nAdded 3573 chunks from https://www.capecodcommission.org/resource-library/file/?url=/dept/commission/team/Website_Resources/housing/CLT-HLB/Cape%20Cod%20CLT%20HLB%20Establishment%20Planning%20Report.pdf\nDone. Total chunks added: 6067\nprocessing row 12/900 idx=11\nScraping: https://en.wikipedia.org/wiki/Hudson%27s_Bay_Company\nAdded 285 chunks from https://en.wikipedia.org/wiki/Hudson%27s_Bay_Company\nScraping: https://financialpost.com/news/retail-marketing/toronto-firm-wants-to-buy-hudsons-bays-brand-charter\nAdded 27 chunks from https://financialpost.com/news/retail-marketing/toronto-firm-wants-to-buy-hudsons-bays-brand-charter\nDone. Total chunks added: 312\nprocessing row 13/900 idx=12\nScraping: https://www.instagram.com/p/ChAWMkCLdHH/\nAdded 1 chunks from https://www.instagram.com/p/ChAWMkCLdHH/\nScraping: https://people.com/lais-ribeiro-is-pregnant-model-expecting-baby-no-2-with-husband-joakim-noah-8698317\nAdded 18 chunks from https://people.com/lais-ribeiro-is-pregnant-model-expecting-baby-no-2-with-husband-joakim-noah-8698317\nDone. Total chunks added: 19\nprocessing row 14/900 idx=13\nScraping: https://variety.com/2019/music/news/quincy-jones-london-show-removes-references-michael-jackson-1203208780/\nAdded 21 chunks from https://variety.com/2019/music/news/quincy-jones-london-show-removes-references-michael-jackson-1203208780/\nScraping: https://www.imdb.com/news/ni62476510/\nAdded 9 chunks from https://www.imdb.com/news/ni62476510/\nDone. Total chunks added: 30\nprocessing row 15/900 idx=14\nScraping: https://www.instituteforgovernment.org.uk/article/explainer/theresa-mays-brexit-deal-final-offer-mps\nAdded 26 chunks from https://www.instituteforgovernment.org.uk/article/explainer/theresa-mays-brexit-deal-final-offer-mps\nScraping: https://en.wikipedia.org/wiki/Brexit_withdrawal_agreement\nAdded 123 chunks from https://en.wikipedia.org/wiki/Brexit_withdrawal_agreement\nDone. Total chunks added: 149\nprocessing row 16/900 idx=15\nScraping: https://scholarlycommons.law.emory.edu/cgi/viewcontent.cgi?article=1004&context=elj\nAdded 1072 chunks from https://scholarlycommons.law.emory.edu/cgi/viewcontent.cgi?article=1004&context=elj\nScraping: https://www.law.nyu.edu/sites/default/files/upload_documents/CLE%20Materials%20Packet.pdf\nAdded 4857 chunks from https://www.law.nyu.edu/sites/default/files/upload_documents/CLE%20Materials%20Packet.pdf\nDone. Total chunks added: 5929\nprocessing row 17/900 idx=16\nScraping: https://www.brookings.edu/articles/oge-director-warns-trumps-plan-insufficient/\nAdded 14 chunks from https://www.brookings.edu/articles/oge-director-warns-trumps-plan-insufficient/\nScraping: https://www.oge.gov/web/oge.nsf/News%20Releases/8A3A4F388D2B749C852585B6005A19A3/$FILE/Remarks%20of%20W%20M%20Shaub%20Jr%20(1).pdf?open\nAdded 80 chunks from https://www.oge.gov/web/oge.nsf/News%20Releases/8A3A4F388D2B749C852585B6005A19A3/$FILE/Remarks%20of%20W%20M%20Shaub%20Jr%20(1).pdf?open\nDone. Total chunks added: 94\nprocessing row 18/900 idx=17\nScraping: https://georgetownlawtechreview.org/german-antitrust-authority-issues-first-blow-to-facebooks-cross-application-data-integration/GLTR-03-2019/\nAdded 12 chunks from https://georgetownlawtechreview.org/german-antitrust-authority-issues-first-blow-to-facebooks-cross-application-data-integration/GLTR-03-2019/\nScraping: https://www.ag.state.mn.us/office/complaint.asp\nAdded 30 chunks from https://www.ag.state.mn.us/office/complaint.asp\nDone. Total chunks added: 42\nprocessing row 19/900 idx=18\nScraping: https://www.dhs.gov/archive/news/2021/08/02/dhs-partners-girl-scouts-usa-launch-2021-girl-scout-cyber-awareness-challenge\nAdded 16 chunks from https://www.dhs.gov/archive/news/2021/08/02/dhs-partners-girl-scouts-usa-launch-2021-girl-scout-cyber-awareness-challenge\nScraping: https://www.mscyberinitiative.org/news/2025/07/mississippi-cyber-initiative-hosts-2025-girl-scouts-cyber-challenge-showcasing-ai\nAdded 10 chunks from https://www.mscyberinitiative.org/news/2025/07/mississippi-cyber-initiative-hosts-2025-girl-scouts-cyber-challenge-showcasing-ai\nDone. Total chunks added: 26\nprocessing row 20/900 idx=19\nScraping: https://en.wikipedia.org/wiki/Only_Yesterday_(1991_film)\nAdded 85 chunks from https://en.wikipedia.org/wiki/Only_Yesterday_(1991_film)\nScraping: https://medium.com/@laura.e920/the-hidden-beauty-of-only-yesterday-isao-takahatas-overlooked-ghibli-masterpiece-c846a7b6aad9\nError scraping https://medium.com/@laura.e920/the-hidden-beauty-of-only-yesterday-isao-takahatas-overlooked-ghibli-masterpiece-c846a7b6aad9: 429 Client Error: Too Many Requests for url: https://medium.com/@laura.e920/the-hidden-beauty-of-only-yesterday-isao-takahatas-overlooked-ghibli-masterpiece-c846a7b6aad9\nSkip https://medium.com/@laura.e920/the-hidden-beauty-of-only-yesterday-isao-takahatas-overlooked-ghibli-masterpiece-c846a7b6aad9: no content or error\nDone. Total chunks added: 85\nprocessing row 21/900 idx=20\nScraping: https://www.nato.int/cps/en/natohq/topics_49198.htm\nError scraping https://www.nato.int/cps/en/natohq/topics_49198.htm: 403 Client Error: Forbidden for url: https://www.nato.int/cps/en/natohq/topics_49198.htm\nSkip https://www.nato.int/cps/en/natohq/topics_49198.htm: no content or error\nScraping: https://www.reuters.com/markets/europe/trumps-nato-spending-demands-could-hit-europes-credit-ratings-says-sp-global-2025-02-14/\nError scraping https://www.reuters.com/markets/europe/trumps-nato-spending-demands-could-hit-europes-credit-ratings-says-sp-global-2025-02-14/: 401 Client Error: HTTP Forbidden for url: https://www.reuters.com/markets/europe/trumps-nato-spending-demands-could-hit-europes-credit-ratings-says-sp-global-2025-02-14/\nSkip https://www.reuters.com/markets/europe/trumps-nato-spending-demands-could-hit-europes-credit-ratings-says-sp-global-2025-02-14/: no content or error\nDone. Total chunks added: 0\nprocessing row 22/900 idx=21\nScraping: https://en.wikipedia.org/wiki/Camp_Fire_(2018)\nAdded 262 chunks from https://en.wikipedia.org/wiki/Camp_Fire_(2018)\nScraping: https://www.buttecounty.net/342/Camp-Fire\nAdded 23 chunks from https://www.buttecounty.net/342/Camp-Fire\nDone. Total chunks added: 285\nprocessing row 23/900 idx=22\nScraping: https://www.justice.gov/archives/opa/pr/wells-fargo-agrees-pay-3-billion-resolve-criminal-and-civil-investigations-sales-practices\nAdded 33 chunks from https://www.justice.gov/archives/opa/pr/wells-fargo-agrees-pay-3-billion-resolve-criminal-and-civil-investigations-sales-practices\nScraping: https://www.consumerfinance.gov/about-us/newsroom/cfpb-orders-wells-fargo-to-pay-37-billion-for-widespread-mismanagement-of-auto-loans-mortgages-and-deposit-accounts/\nAdded 25 chunks from https://www.consumerfinance.gov/about-us/newsroom/cfpb-orders-wells-fargo-to-pay-37-billion-for-widespread-mismanagement-of-auto-loans-mortgages-and-deposit-accounts/\nDone. Total chunks added: 58\nprocessing row 24/900 idx=23\nScraping: https://www.reddit.com/r/artbusiness/comments/1d4v6cs/show_me_your_portfolio_i_need_inspiration_and_help/\nError scraping https://www.reddit.com/r/artbusiness/comments/1d4v6cs/show_me_your_portfolio_i_need_inspiration_and_help/: 403 Client Error: Blocked for url: https://www.reddit.com/r/artbusiness/comments/1d4v6cs/show_me_your_portfolio_i_need_inspiration_and_help/\nSkip https://www.reddit.com/r/artbusiness/comments/1d4v6cs/show_me_your_portfolio_i_need_inspiration_and_help/: no content or error\nScraping: https://www.portfoliobox.com/examples?type=artist\nAdded 5 chunks from https://www.portfoliobox.com/examples?type=artist\nDone. Total chunks added: 5\nprocessing row 25/900 idx=24\nScraping: https://www.sciencedirect.com/science/article/pii/S0301421524000843\nError scraping https://www.sciencedirect.com/science/article/pii/S0301421524000843: 400 Client Error: Bad Request for url: https://www.sciencedirect.com/unsupported_browser\nSkip https://www.sciencedirect.com/science/article/pii/S0301421524000843: no content or error\nScraping: https://www.iea.org/reports/global-ev-outlook-2024/trends-in-the-electric-vehicle-industry\nError scraping https://www.iea.org/reports/global-ev-outlook-2024/trends-in-the-electric-vehicle-industry: 403 Client Error: Forbidden for url: https://www.iea.org/reports/global-ev-outlook-2024/trends-in-the-electric-vehicle-industry\nSkip https://www.iea.org/reports/global-ev-outlook-2024/trends-in-the-electric-vehicle-industry: no content or error\nDone. Total chunks added: 0\nprocessing row 26/900 idx=25\nScraping: https://jlc.org/news/riot-broke-out-during-boxing-match-philadelphias-juvenile-detention-center-now-its-provisional\nError scraping https://jlc.org/news/riot-broke-out-during-boxing-match-philadelphias-juvenile-detention-center-now-its-provisional: 403 Client Error: Forbidden for url: https://jlc.org/news/riot-broke-out-during-boxing-match-philadelphias-juvenile-detention-center-now-its-provisional\nSkip https://jlc.org/news/riot-broke-out-during-boxing-match-philadelphias-juvenile-detention-center-now-its-provisional: no content or error\nScraping: https://www.koat.com/article/juvenile-detention-center-disturbance-happening/46224199\nAdded 23 chunks from https://www.koat.com/article/juvenile-detention-center-disturbance-happening/46224199\nDone. Total chunks added: 23\nprocessing row 27/900 idx=26\nScraping: https://www.boxingscene.com/articles/dominic-breazeale-sues-deontay-wilder-over-hotel-brawl\nAdded 8 chunks from https://www.boxingscene.com/articles/dominic-breazeale-sues-deontay-wilder-over-hotel-brawl\nScraping: https://www.premierboxingchampions.com/news/wilder-vs-breazeale-bad-blood-brooklyn\nAdded 20 chunks from https://www.premierboxingchampions.com/news/wilder-vs-breazeale-bad-blood-brooklyn\nDone. Total chunks added: 28\nprocessing row 28/900 idx=27\nScraping: https://hls.harvard.edu/today/brexit-implications-uk-financial-services-industry/\nAdded 21 chunks from https://hls.harvard.edu/today/brexit-implications-uk-financial-services-industry/\nScraping: https://www.tandfonline.com/doi/full/10.1080/13563467.2021.1994540\nError scraping https://www.tandfonline.com/doi/full/10.1080/13563467.2021.1994540: 403 Client Error: Forbidden for url: https://www.tandfonline.com/doi/full/10.1080/13563467.2021.1994540\nSkip https://www.tandfonline.com/doi/full/10.1080/13563467.2021.1994540: no content or error\nDone. Total chunks added: 21\nprocessing row 29/900 idx=28\nprocessing row 30/900 idx=29\nScraping: https://www.burlingtonnc.gov/2605/Black-Friday-Going-Out-of-Style-An-Exami\nAdded 15 chunks from https://www.burlingtonnc.gov/2605/Black-Friday-Going-Out-of-Style-An-Exami\nScraping: https://wisernotify.com/blog/black-friday-history/\nAdded 52 chunks from https://wisernotify.com/blog/black-friday-history/\nDone. Total chunks added: 67\nprocessing row 31/900 idx=30\nprocessing row 32/900 idx=31\nprocessing row 33/900 idx=32\nprocessing row 34/900 idx=33\nprocessing row 35/900 idx=34\nprocessing row 36/900 idx=35\nprocessing row 37/900 idx=36\nprocessing row 38/900 idx=37\nprocessing row 39/900 idx=38\nprocessing row 40/900 idx=39\nprocessing row 41/900 idx=40\nprocessing row 42/900 idx=41\nprocessing row 43/900 idx=42\nprocessing row 44/900 idx=43\nprocessing row 45/900 idx=44\nprocessing row 46/900 idx=45\nprocessing row 47/900 idx=46\nprocessing row 48/900 idx=47\nprocessing row 49/900 idx=48\nprocessing row 50/900 idx=49\nprocessing row 51/900 idx=50\nprocessing row 52/900 idx=51\nprocessing row 53/900 idx=52\nprocessing row 54/900 idx=53\nprocessing row 55/900 idx=54\nprocessing row 56/900 idx=55\nprocessing row 57/900 idx=56\nprocessing row 58/900 idx=57\nprocessing row 59/900 idx=58\nprocessing row 60/900 idx=59\nprocessing row 61/900 idx=60\nprocessing row 62/900 idx=61\nprocessing row 63/900 idx=62\nprocessing row 64/900 idx=63\nprocessing row 65/900 idx=64\nprocessing row 66/900 idx=65\nprocessing row 67/900 idx=66\nprocessing row 68/900 idx=67\nprocessing row 69/900 idx=68\nprocessing row 70/900 idx=69\nprocessing row 71/900 idx=70\nprocessing row 72/900 idx=71\nprocessing row 73/900 idx=72\nprocessing row 74/900 idx=73\nprocessing row 75/900 idx=74\nprocessing row 76/900 idx=75\nprocessing row 77/900 idx=76\nprocessing row 78/900 idx=77\nprocessing row 79/900 idx=78\nprocessing row 80/900 idx=79\nprocessing row 81/900 idx=80\nprocessing row 82/900 idx=81\nprocessing row 83/900 idx=82\nprocessing row 84/900 idx=83\nprocessing row 85/900 idx=84\nprocessing row 86/900 idx=85\nprocessing row 87/900 idx=86\nprocessing row 88/900 idx=87\nprocessing row 89/900 idx=88\nprocessing row 90/900 idx=89\nprocessing row 91/900 idx=90\nprocessing row 92/900 idx=91\nScraping: https://abcnews.go.com/Politics/gov-brian-sandoval-declines-consideration-supreme-court-opening/story?id=37195560\nAdded 9 chunks from https://abcnews.go.com/Politics/gov-brian-sandoval-declines-consideration-supreme-court-opening/story?id=37195560\nScraping: https://www.washingtonpost.com/news/powerpost/wp/2016/02/24/brian-sandoval-republican-governor-of-nevada-is-being-vetted-for-supreme-court-vacancy/\nError scraping https://www.washingtonpost.com/news/powerpost/wp/2016/02/24/brian-sandoval-republican-governor-of-nevada-is-being-vetted-for-supreme-court-vacancy/: HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=15)\nSkip https://www.washingtonpost.com/news/powerpost/wp/2016/02/24/brian-sandoval-republican-governor-of-nevada-is-being-vetted-for-supreme-court-vacancy/: no content or error\nDone. Total chunks added: 9\nprocessing row 93/900 idx=92\nprocessing row 94/900 idx=93\nprocessing row 95/900 idx=94\nprocessing row 96/900 idx=95\nprocessing row 97/900 idx=96\nprocessing row 98/900 idx=97\nprocessing row 99/900 idx=98\nprocessing row 100/900 idx=99\nprocessing row 101/900 idx=100\nprocessing row 102/900 idx=101\nprocessing row 103/900 idx=102\nprocessing row 104/900 idx=103\nprocessing row 105/900 idx=104\nprocessing row 106/900 idx=105\nprocessing row 107/900 idx=106\nprocessing row 108/900 idx=107\nprocessing row 109/900 idx=108\nprocessing row 110/900 idx=109\nprocessing row 111/900 idx=110\nprocessing row 112/900 idx=111\nprocessing row 113/900 idx=112\nprocessing row 114/900 idx=113\nprocessing row 115/900 idx=114\nprocessing row 116/900 idx=115\nprocessing row 117/900 idx=116\nprocessing row 118/900 idx=117\nprocessing row 119/900 idx=118\nprocessing row 120/900 idx=119\nprocessing row 121/900 idx=120\nprocessing row 122/900 idx=121\nprocessing row 123/900 idx=122\nprocessing row 124/900 idx=123\nprocessing row 125/900 idx=124\nprocessing row 126/900 idx=125\nprocessing row 127/900 idx=126\nprocessing row 128/900 idx=127\nprocessing row 129/900 idx=128\nprocessing row 130/900 idx=129\nprocessing row 131/900 idx=130\nprocessing row 132/900 idx=131\nprocessing row 133/900 idx=132\nprocessing row 134/900 idx=133\nprocessing row 135/900 idx=134\nprocessing row 136/900 idx=135\nprocessing row 137/900 idx=136\nprocessing row 138/900 idx=137\nprocessing row 139/900 idx=138\nprocessing row 140/900 idx=139\nprocessing row 141/900 idx=140\nprocessing row 142/900 idx=141\nprocessing row 143/900 idx=142\nprocessing row 144/900 idx=143\nprocessing row 145/900 idx=144\nprocessing row 146/900 idx=145\nprocessing row 147/900 idx=146\nprocessing row 148/900 idx=147\nprocessing row 149/900 idx=148\nprocessing row 150/900 idx=149\nprocessing row 151/900 idx=150\nprocessing row 152/900 idx=151\nprocessing row 153/900 idx=152\nprocessing row 154/900 idx=153\nprocessing row 155/900 idx=154\nprocessing row 156/900 idx=155\nprocessing row 157/900 idx=156\nprocessing row 158/900 idx=157\nprocessing row 159/900 idx=158\nprocessing row 160/900 idx=159\nprocessing row 161/900 idx=160\nprocessing row 162/900 idx=161\nprocessing row 163/900 idx=162\nprocessing row 164/900 idx=163\nprocessing row 165/900 idx=164\nprocessing row 166/900 idx=165\nprocessing row 167/900 idx=166\nprocessing row 168/900 idx=167\nprocessing row 169/900 idx=168\nprocessing row 170/900 idx=169\nprocessing row 171/900 idx=170\nprocessing row 172/900 idx=171\nprocessing row 173/900 idx=172\nprocessing row 174/900 idx=173\nprocessing row 175/900 idx=174\nprocessing row 176/900 idx=175\nprocessing row 177/900 idx=176\nprocessing row 178/900 idx=177\nprocessing row 179/900 idx=178\nprocessing row 180/900 idx=179\nprocessing row 181/900 idx=180\nprocessing row 182/900 idx=181\nprocessing row 183/900 idx=182\nprocessing row 184/900 idx=183\nprocessing row 185/900 idx=184\nprocessing row 186/900 idx=185\nprocessing row 187/900 idx=186\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''#text preprocessing\n",
        "\n",
        "text = \"Hello My name is Vinayak Trivedi.\"\n",
        "text = text.lower()\n",
        "\n",
        "#stopwords removal only for sentence scoring -> for summarisation purposes we need the stopwords as well.\n",
        "stopwords_set = set(stopwords.words('english'))\n",
        "words = nltk.word_tokenize(text)\n",
        "filtered_words = [word for word in words if word not in stopwords_set]\n",
        "text = \" \".join(filtered_words)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "expanded_words = [contractions.fix(word) for word in text.split()]\n",
        "text = \" \".join(expanded_words)\n",
        "\n",
        "# I expanded the text and then lemmatized as the lemmatizer takes \"don't\" and \"do not\" separately\n",
        "lematized = [lemmatizer.lemmatize(word) for word in text.split()]\n",
        "text = \" \".join(lematized)\n",
        "\n",
        "\n",
        "sentences = nltk.sent_tokenize(text)'''"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-09-23T17:16:58.627Z"
        },
        "id": "bEeAtqhQafzT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df3.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-09-23T17:16:58.627Z"
        },
        "id": "LcyV2ul-afzT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"csvgen.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "kWZq6VHtafzT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4ebb3c38-f2e6-4ecf-f50a-15e4a922d1bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Title  \\\n",
              "0                 German home prices rise 3.2% in Q2   \n",
              "1                 US inflation heats up in June 2025   \n",
              "2                 Wall Street closes at record highs   \n",
              "3  BMO to sell US branches after Bank of the West...   \n",
              "4                Romania readies year-end bond deals   \n",
              "\n",
              "                                             Article Label  \n",
              "0  Home prices in Germany rose by 3.2% in the sec...    no  \n",
              "1  US consumer inflation accelerated in June 2025...    no  \n",
              "2  Major U.S. stock indexes hit new record highs ...    no  \n",
              "3  Bank of Montreal announced plans to sell sever...    no  \n",
              "4  Romania said it plans to issue bonds and buyba...    no  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3aa4f1c5-38aa-49a9-bbb9-8fc3309c2a29\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Article</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>German home prices rise 3.2% in Q2</td>\n",
              "      <td>Home prices in Germany rose by 3.2% in the sec...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US inflation heats up in June 2025</td>\n",
              "      <td>US consumer inflation accelerated in June 2025...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wall Street closes at record highs</td>\n",
              "      <td>Major U.S. stock indexes hit new record highs ...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BMO to sell US branches after Bank of the West...</td>\n",
              "      <td>Bank of Montreal announced plans to sell sever...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Romania readies year-end bond deals</td>\n",
              "      <td>Romania said it plans to issue bonds and buyba...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3aa4f1c5-38aa-49a9-bbb9-8fc3309c2a29')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3aa4f1c5-38aa-49a9-bbb9-8fc3309c2a29 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3aa4f1c5-38aa-49a9-bbb9-8fc3309c2a29');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-883bba3a-c9b4-46a8-aee9-d326a138f09b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-883bba3a-c9b4-46a8-aee9-d326a138f09b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-883bba3a-c9b4-46a8-aee9-d326a138f09b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 79,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 79,\n        \"samples\": [\n          \"WHO endorses obesity drugs\",\n          \"German home prices rise 3.2% in Q2\",\n          \"Oil edges higher on supply fears\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Article\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 79,\n        \"samples\": [\n          \"WHO experts recommended the use of certain weight-loss drugs (GLP-1 receptor agonists) for treating severe obesity in adults. The panel classified obesity as a chronic disease and endorsed these medications for people with BMI over 30, alongside diet and exercise. The drugs, however, were not added to WHO\\u2019s essential medicines list due to high cost, although their role in long-term obesity management was stressed.\",\n          \"Home prices in Germany rose by 3.2% in the second quarter of 2025, marking a third straight quarterly gain after a multi-year slump. Analysts note the increase is smaller than earlier growth, meaning much of the previous decline remains. The property sector looks to be stabilizing, but prices have yet to return to pre-downturn levels.\",\n          \"Oil prices climbed in late 2025 due to renewed supply concerns in the Middle East. Brent crude moved back toward $90 per barrel after news of outages in a key OPEC producer, even as global demand was softening. Traders noted that any significant disruption in Middle Eastern exports could quickly tighten the market and boost prices further.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" \\\"no\\\"\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "execution_count": null
    }
  ]
}